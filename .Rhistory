guides(fill=FALSE)
#show change through time from earliest to latest
dat$Year <- sort(dat$Year,decreasing=F)
#filter data for only Great Lakes lat and long
BorderingGreatLakes <- c("New York","Pennsylvania","Ohio","Indiana","Michigan","Illinois","Wisconsin","Minnesota")
PlottingBorder <- map_data("state", region=BorderingGreatLakes)
Borders <- ggplot(data = PlottingBorder) +
geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE)+scale_y_continuous(breaks=seq(from=30,to=50,by=1))+scale_x_continuous(breaks=seq(from=-100,to=-70,by=1))
Superior <- dat %>% filter(Latitude>=46 & Latitude<=50) %>% filter(Longitude<=-84.5 & Longitude>=-92)
map4 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)
Michigan <- dat %>% filter(Latitude>=42.5 & Latitude<=46) %>% filter(Longitude<=-84.5 & Longitude>=-88)
map5 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Michigan,alpha=0.2)
Huron <- dat %>% filter(Latitude>=43 & Latitude<=46) %>% filter(Longitude<=-81.5 & Longitude>=-84)
map6 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Huron,alpha=0.2)
Erie <- dat %>% filter(Latitude>=41.5 & Latitude<=43) %>% filter(Longitude<=-79 & Longitude>=-84)
map7 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Erie,alpha=0.2)
Ontario <- dat %>% filter(Latitude>=43.25 & Latitude<=44) %>% filter(Longitude<=-78 & Longitude>=-80)
map8 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Ontario,alpha=0.2)
#all great Lakes plotted
GreatLakes <- Borders +
geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="blue"),data=Michigan,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="green"),data=Huron,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="yellow"),data=Erie,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="purple"),data=Ontario,alpha=0.2)
GreatLakes
dat <- read.csv("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/NAS-Data-Download.csv")
library(dplyr)
library(ggplot2)
#remove 0,0 coordinate row
dat <- dat[-5810,]
library(ggplot2)
library(maps)
library(gganimate)
library(dplyr)
## This is the third 8 years of the data (2009-2015)
sup_counts_T8 <-nrow(table(SuperiorThird8$HUC.8.Number))
mich_counts_T8 <-nrow(table(MichiganThird8$HUC.8.Number))
huron_counts_T8<-nrow(table(HuronThird8$HUC.8.Number))
erie_counts_T8 <- nrow(table(ErieThird8$HUC.8.Number))
ont_counts_T8 <- nrow(table(OntarioThird8$HUC.8.Number))
zm_HUC_occurances_T8 <-c(sup_counts_T8, mich_counts_T8, huron_counts_T8, erie_counts_T8, ont_counts_T8)
sizeDatT8 <- data.frame(size_of_lake, zm_HUC_occurances_T8)
ggplot(sizeDatT8, aes(x=size_of_lake, y=zm_HUC_occurances_T8)) + geom_point() + geom_smooth(method = "lm") + labs(title="Size of Lake vs. HUC Occurances", subtitle="From USGS Zebra Mussel Dataset For Third 8 Years", y="HUC Occurances", x="Size of Lake")
#Superior, Michigan, Huron, Erie, Ontario sizes in square miles
size_of_lake <- c(31700, 22300, 23000, 9910, 7340)
sup_counts <-nrow(table(Superior$HUC.8.Number))
mich_counts <-nrow(table(Michigan$HUC.8.Number))
#Plot number of zebra mussels sightings per year
Summarize_sightings_by_year_month <- dat %>% count(Year, Month,State)
plot(Summarize_sightings_by_year_month$Year,Summarize_sightings_by_year_month$n)
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year)) +
geom_bar(position="dodge", stat="identity")
dat <- read.csv("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/NAS-Data-Download.csv")
#remove 0,0 coordinate row
dat <- dat[-5810,]
library(ggplot2)
library(maps)
library(gganimate)
library(dplyr)
#map of the 50 states
US <- map_data("state")
states <- ggplot(data = US) +
geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE)
#show change through time from earliest to latest
dat$Year <- sort(dat$Year,decreasing=F)
#Plot number of zebra mussels sightings per year
Summarize_sightings_by_year_month <- dat %>% count(Year, Month,State)
plot(Summarize_sightings_by_year_month$Year,Summarize_sightings_by_year_month$n)
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year)) +
geom_bar(position="dodge", stat="identity")
##  Temperature data
library(readxl)
lakes_92_18 <- read_excel("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/great lakes avg temp 1992-2018.xlsx")
every_lake <- read_excel("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/every lake 1995-2018.xlsx")
#This graph shows the average temperatures for the lakes over the course of the year
#IT'S A GOOD GRAPH
plot(lakes_92_18$Day,lakes_92_18$Superior, col= "blue", xlim= c(1,365), ylim= c(0,30),
xlab= "Day of the Year", ylab= "Temperature (Celsius)", main= "Average Temp 1992-2018")
points(lakes_92_18$Day,lakes_92_18$Michigan, col= "orange")
points(lakes_92_18$Day,lakes_92_18$Huron, col="green" )
points(lakes_92_18$Day,lakes_92_18$Erie, col= "red")
points(lakes_92_18$Day,lakes_92_18$Ontario, col= "purple")
legend(0, 27, legend=c("Superior","Michigan","Huron","Erie","Ontario"),
col=c("blue","orange","green","red","purple"), lty=1, title= "Lake")
# #This shows the consistency of the temperature of Lake Michigan over the years
Mich_Temp <- every_lake%>%
select(Year,Day,Mich.)
#
plot(Temp)
#
ggplot(Temp, aes(x= Year, y= Mich.))+geom_point()
every_lake <- read_excel("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/every lake 1995-2018.xlsx")
View(lakes_92_18)
dat <- read.csv("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/NAS-Data-Download.csv")
#remove 0,0 coordinate row
dat <- dat[-5810,]
library(ggplot2)
library(maps)
library(gganimate)
library(dplyr)
#map of the 50 states
US <- map_data("state")
states <- ggplot(data = US) +
geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE)
#show change through time from earliest to latest
dat$Year <- sort(dat$Year,decreasing=F)
map1 <- states + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=dat,alpha=0.2)+transition_states(dat$Year)
#population in 2019
latest <- dat[dat$Year=="2019",]
map2 <- states + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=latest,alpha=0.2)
#animation of only those established or collected after 2000
established_collected_post_2000 <- filter(dat[dat$Year>=2000,]) %>%
filter(Status=="established"|Status=="collected")
established_collected_post_2000$Year <- sort(established_collected_post_2000$Year,decreasing=F)
map3 <- states + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=established_collected_post_2000,alpha=0.2)+transition_states(established_collected_post_2000$Year)+shadow_mark()
#Plot number of zebra mussels sightings per year
Summarize_sightings_by_year_month <- dat %>% count(Year, Month,State)
plot(Summarize_sightings_by_year_month$Year,Summarize_sightings_by_year_month$n)
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year)) +
geom_bar(position="dodge", stat="identity")
#filter data for only Great Lakes lat and long
BorderingGreatLakes <- c("New York","Pennsylvania","Ohio","Indiana","Michigan","Illinois","Wisconsin","Minnesota")
PlottingBorder <- map_data("state", region=BorderingGreatLakes)
Borders <- ggplot(data = PlottingBorder) +
geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE)+scale_y_continuous(breaks=seq(from=30,to=50,by=1))+scale_x_continuous(breaks=seq(from=-100,to=-70,by=1))
Superior <- dat %>% filter(Latitude>=46 & Latitude<=50) %>% filter(Longitude<=-84.5 & Longitude>=-92)
map4 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)
Michigan <- dat %>% filter(Latitude>=42.5 & Latitude<=46) %>% filter(Longitude<=-84.5 & Longitude>=-88)
map5 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Michigan,alpha=0.2)
Huron <- dat %>% filter(Latitude>=43 & Latitude<=46) %>% filter(Longitude<=-81.5 & Longitude>=-84)
map6 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Huron,alpha=0.2)
Erie <- dat %>% filter(Latitude>=41.5 & Latitude<=43) %>% filter(Longitude<=-79 & Longitude>=-84)
map7 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Erie,alpha=0.2)
Ontario <- dat %>% filter(Latitude>=43.25 & Latitude<=44) %>% filter(Longitude<=-78 & Longitude>=-80)
map8 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Ontario,alpha=0.2)
#all great Lakes plotted
GreatLakes <- Borders +
geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="blue"),data=Michigan,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="green"),data=Huron,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="yellow"),data=Erie,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="purple"),data=Ontario,alpha=0.2)
```
#Linear Regression of Size of Lake and HUC Counts
```{r SizeLR, echo=FALSE}
#Superior, Michigan, Huron, Erie, Ontario sizes in square miles
size_of_lake <- c(31700, 22300, 23000, 9910, 7340)
sup_counts <-nrow(table(Superior$HUC.8.Number))
mich_counts <-nrow(table(Michigan$HUC.8.Number))
huron_counts <-nrow(table(Huron$HUC.8.Number))
erie_counts <- nrow(table(Erie$HUC.8.Number))
ont_counts <- nrow(table(Ontario$HUC.8.Number))
zm_HUC_occurances <-c(sup_counts, mich_counts, huron_counts, erie_counts, ont_counts)
sizeDat <- data.frame(size_of_lake, zm_HUC_occurances)
HUCmodelSize <- lm(zm_HUC_occurances~size_of_lake, sizeDat)
summary(HUCmodelSize)
sizeCoef <- coef(HUCmodelSize)[2]
view(zm_HUC_occurances)
library(tibble)
view(zm_HUC_occurances)
view(dat)
sup_counts <-nrow(unique(Superior$Specimen.Number))
mich_counts <-nrow(unique(Michigan$Specimen.Number))
huron_counts <-nrow(unique(Huron$Specimen.Number))
erie_counts <- nrow(unique(Erie$Specimen.Number))
ont_counts <- nrow(uniqie(Ontario$Specimen.Number))
zm_occurances <-c(sup_counts, mich_counts, huron_counts, erie_counts, ont_counts
ont_counts <- nrow(unique(Ontario$Specimen.Number))
zm_occurances <-c(sup_counts, mich_counts, huron_counts, erie_counts, ont_counts
zm_occurances <-c(sup_counts, mich_counts, huron_counts, erie_counts, ont_counts)
zm_occurances <- c(sup_counts, mich_counts, huron_counts, erie_counts, ont_counts)
view(zm_occurances)
sup_counts
sup_counts <-nrow(Superior$Specimen.Number)
sup_counts
Superior
view(Superior)
mich_counts <-(unique(Michigan$Specimen.Number))
view(mich_counts)
sup_occ <- unique(Michigan$Specimen.Number)
mich_occ <- unique(Michigan$Specimen.Number)
huron_occ <- (unique(Huron$Specimen.Number)
ont_occ <- unique(Ontario$Specimen.Number)
huron_occ <- unique(Huron$Specimen.Number)
erie_occ <- unique(Erie$Specimen.Number)
ont_occ <- unique(Ontario$Specimen.Number)
zm_occ <- c(sup_occ, mich_occ, huron_occ, erie_occ, ont_occ)
zm_occ
view(zm_occ)
sup_occ <- unique(Superior$Specimen.Number)
mich_occ <- unique(Michigan$Specimen.Number)
huron_occ <- unique(Huron$Specimen.Number)
erie_occ <- unique(Erie$Specimen.Number)
ont_occ <- unique(Ontario$Specimen.Number)
view(sup-occ)
view(sup_occ)
view(mich_occ)
count(sup_occ)
?summarise
n(sup_occ)
summarize(sup_occ,n())
nrow(table(sup_occ))
nrow(table(mich_occ))
nrow(table(huron_occ))
nrow(table(erie_occ))
nrow(table(ont_occ))
table(sup_occ)
SupOcc <- nrow(table(sup_occ))
MichOcc <- nrow(table(mich_occ))
HurOcc <- nrow(table(huron_occ))
EriOcc <-nrow(table(erie_occ))
Ont_Occ <- nrow(table(ont_occ))
OntOcc <- nrow(table(ont_occ))
zm_occ <- c(SupOcc, MichOcc, HurOcc, EriOcc, OntOcc)
table(zm_occ)
view(dat)
#all great Lakes plotted
GreatLakes <- Borders +
geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="blue"),data=Michigan,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="green"),data=Huron,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="yellow"),data=Erie,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="purple"),data=Ontario,alpha=0.2)
GreatLakes
dat <- read.csv("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/NAS-Data-Download.csv")
library(dplyr)
library(ggplot2)
```
```{r, echo = FALSE, eval=FALSE}
# Checking to unique HUC ID Numbers
as.data.frame(table(dat$HUC.8.Number))
# There are 350 unique HUC ID numbers
# That means there are 350 different locations for this data
```
```{r, echo = FALSE}
#remove 0,0 coordinate row
dat <- dat[-5810,]
library(ggplot2)
library(maps)
library(gganimate)
library(dplyr)
#Plot number of zebra mussels sightings per year
Summarize_sightings_by_year_month <- dat %>% count(Year, Month,State)
plot(Summarize_sightings_by_year_month$Year,Summarize_sightings_by_year_month$n)
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year)) +
geom_bar(position="dodge", stat="identity")
Summarize_sightings_by_year_month
lm(n~Year, Summarize_sightings_by_year_month)
CountYear <- lm(n~Year, Summarize_sightings_by_year_month)
summary(CountYear)
ggplot(Summarize_sightings_by_year_month, aes(x=Summarize_sightings_by_year_month$Year, y=Summarize_sightings_by_year_month$n)) + geom_point() + geom_smooth(method = "lm") + labs(title="Occurrences By Year", y="Count",
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year))
ggplot(Summarize_sightings_by_year_month, aes(x=Summarize_sightings_by_year_month$Year, y=Summarize_sightings_by_year_month$n)) + geom_point() + geom_smooth(method = "lm") + labs(title="Occurrences By Year", y="Count",
ggplot(Summarize_sightings_by_year_month, aes(x=Summarize_sightings_by_year_month$Year, y=Summarize_sightings_by_year_month$n)) + geom_point() + geom_smooth(method = "lm") + labs(title="Occurrences By Year", y="Count")
ggplot(Summarize_sightings_by_year_month, aes(x=Summarize_sightings_by_year_month$Year, y=Summarize_sightings_by_year_month$n)) + geom_point() + geom_smooth(method = "lm") + labs(title="Occurrences By Year", y="Count",x="Year")
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year))
ggplot(Summarize_sightings_by_year_month, aes(fill=Summarize_sightings_by_year_month$State, y=Summarize_sightings_by_year_month$n, x=Summarize_sightings_by_year_month$Year)) + geom_bar(position="dodge", stat="identity")
#number of specimens found in each lake`
sup_occ <- unique(Superior$Specimen.Number)
mich_occ <- unique(Michigan$Specimen.Number)
huron_occ <- unique(Huron$Specimen.Number)
erie_occ <- unique(Erie$Specimen.Number)
ont_occ <- unique(Ontario$Specimen.Number)
zm_occ <- c(sup_occ, mich_occ, huron_occ, erie_occ, ont_occ)
SupOcc <- nrow(table(sup_occ))
MichOcc <- nrow(table(mich_occ))
HurOcc <- nrow(table(huron_occ))
EriOcc <- nrow(table(erie_occ))
OntOcc <- nrow(table(ont_occ))
zm_occ <- c(SupOcc, MichOcc, HurOcc, EriOcc, OntOcc)
Superior <- dat %>% filter(Latitude>=46 & Latitude<=50) %>% filter(Longitude<=-84.5 & Longitude>=-92)
map4 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)
Michigan <- dat %>% filter(Latitude>=42.5 & Latitude<=46) %>% filter(Longitude<=-84.5 & Longitude>=-88)
#filter data for only Great Lakes lat and long
BorderingGreatLakes <- c("New York","Pennsylvania","Ohio","Indiana","Michigan","Illinois","Wisconsin","Minnesota")
PlottingBorder <- map_data("state", region=BorderingGreatLakes)
Borders <- ggplot(data = PlottingBorder) +
geom_polygon(aes(x = long, y = lat, group = group), color = "white") +
coord_fixed(1.3) +
guides(fill=FALSE)+scale_y_continuous(breaks=seq(from=30,to=50,by=1))+scale_x_continuous(breaks=seq(from=-100,to=-70,by=1))
Superior <- dat %>% filter(Latitude>=46 & Latitude<=50) %>% filter(Longitude<=-84.5 & Longitude>=-92)
map4 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)
Michigan <- dat %>% filter(Latitude>=42.5 & Latitude<=46) %>% filter(Longitude<=-84.5 & Longitude>=-88)
map5 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Michigan,alpha=0.2)
Huron <- dat %>% filter(Latitude>=43 & Latitude<=46) %>% filter(Longitude<=-81.5 & Longitude>=-84)
map6 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Huron,alpha=0.2)
Erie <- dat %>% filter(Latitude>=41.5 & Latitude<=43) %>% filter(Longitude<=-79 & Longitude>=-84)
map7 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Erie,alpha=0.2)
Ontario <- dat %>% filter(Latitude>=43.25 & Latitude<=44) %>% filter(Longitude<=-78 & Longitude>=-80)
map8 <- Borders + geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Ontario,alpha=0.2)
#all great Lakes plotted
GreatLakes <- Borders +
geom_point(aes(x=Longitude,y=Latitude,color=Status),data=Superior,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="blue"),data=Michigan,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="green"),data=Huron,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="yellow"),data=Erie,alpha=0.2)+
geom_point(aes(x=Longitude,y=Latitude,color="purple"),data=Ontario,alpha=0.2)
```
```{r}
#number of specimens found in each lake`
sup_occ <- unique(Superior$Specimen.Number)
mich_occ <- unique(Michigan$Specimen.Number)
huron_occ <- unique(Huron$Specimen.Number)
erie_occ <- unique(Erie$Specimen.Number)
ont_occ <- unique(Ontario$Specimen.Number)
zm_occ <- c(sup_occ, mich_occ, huron_occ, erie_occ, ont_occ)
SupOcc <- nrow(table(sup_occ))
MichOcc <- nrow(table(mich_occ))
HurOcc <- nrow(table(huron_occ))
EriOcc <- nrow(table(erie_occ))
OntOcc <- nrow(table(ont_occ))
zm_occ <- c(SupOcc, MichOcc, HurOcc, EriOcc, OntOcc)
zm_occ
dat <- read.csv("C:/Users/kmb057/Documents/FundamentalsQuantReasoning/QuantReasoning/NAS-Data-Download.csv")
install.packages("stringr")
library(stringr)
BiocManager::install("tximport")
BiocManager::install("tximportData")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("DESeq2")
BiocManager::install("tximport")
library(tximport)
library(tximportData)
BiocManager::install("tximportData")
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
install.packages("ggpubr")
library(readr)
install.packages("wesanderson")
## Set your working directory
setwd("~EcologicalGenomics")
## Import the libraries that we're likely to need in this session
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")
## Import the counts matrix
countsTable <- read.table("RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)
## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)
## Import the counts matrix
countsTable <- read.table("C:\Users\kmb057\Documents\GitHub\EcologicalGenomics\RS_counts_samples/RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
## Import the counts matrix
countsTable <- read.table("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)
## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)
## Set your working directory
setwd("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics")
## Import the counts matrix
countsTable <- read.table("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)
## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)
## Let's see how many reads we have from each sample:
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), las=3, cex.names=0.5,names.arg = substring(colnames(countsTableRound),1,13))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd =2)
#What is the average number of counts per gene?
rowSums(countsTableRound)
mean(rowSums(countsTableRound))
median(rowSums(countsTableRound))
#What's the average number of counts per gene per sample?
apply(countsTableRound,2,mean)
## Create a DESeq object and define the experimental design here with the tilde
dds <- DESeqDataSetFromMatrix(countData = countsTableRound,colData = conds, design = ~pop + day + treatment)
dim(dds)
# Filter out genes with few reads
dds <- dds[rowSums(counts(dds)) > 76]
dim(dds)
# Filter out genes with few reads
dds <- dds[rowSums(counts(dds)) > 760]
dim(dds)
dds <- DESeq(dds)
dds
resultsNames(dds)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound,colData = conds, design = ~ climate + day + treatment)
dim(dds)
# List the results you've generated
resultsNames(dds)
# List the results you've generated
resultsNames(dds)
dds <- DESeq(dds)
dds <- DESeqDataSetFromMatrix(countData = countsTableRound,colData = conds, design = ~ climate + day + treatment)
dim(dds)
dds <- DESeq(dds)
# List the results you've generated
resultsNames(dds)
# List the results you've generated
resultsNames(dds)
# Order and list and summarize results from specific contrasts
# Here you set your adjusted p-value cutoff, can make summary tables of the number of genes differentially expressed (up- or down-regulated) for each contrast
res <- results(dds,alpha = 0.05)
# List the results you've generated
resultsNames(dds)
# List the results you've generated
resultsNames(dds)
# Order and list and summarize results from specific contrasts
# Here you set your adjusted p-value cutoff, can make summary tables of the number of genes differentially expressed (up- or down-regulated) for each contrast
res <- results(dds,alpha = 0.05)
res <- res[order(res$padj)]
head(res)
summary(res)
res_treatCD <- results(dds, name="treatment_D_vs_c",alpha=0.05)
res_treatCD <- res_treatCD[order(res_treatCD$padj),]
head(res_treatCD)
res_treatCD <- results(dds, name="treatment_D_vs_c",alpha=0.05)
res_treatCD <- results(dds, name="treatment_D_vs_C",alpha=0.05)
res_treatCD <- res_treatCD[order(res_treatCD$padj),]
head(res_treatCD)
summary(res_treatCD)
##### Data visualization #####
# MA plot
plotMA(res_treatCD,ylim=c(-3,3))
# PCA
vsd <- vst(dds,blind=FALSE)
data <- plotPCA(vsd,intgroup=c("climate","treatment","day")returnData=TRUE)
data <- plotPCA(vsd,intgroup=c("climate","treatment","day"),returnData=TRUE)
ggplot(data, aes(PC1, PC2, color=climate, shape=treatment)) +
geom_point(size=4, alpha=0.85) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
theme_minimal()
data <- plotPCA(vsd,intgroup=c("climate","treatment","day"),returnData=TRUE)
percentVar <- round(100 * attr(data,"percentVar"))
ggplot(data, aes(PC1, PC2, color=climate, shape=treatment)) +
geom_point(size=4, alpha=0.85) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
theme_minimal()
ggplot(data, aes(PC1, PC2, color=climate, shape=treatment)) +
geom_point(size=4, alpha=0.85) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
theme_minimal()
ggplot(data, aes(PC1, PC2, color=day, shape=treatment)) +
geom_point(size=4, alpha=0.85) +
xlab(paste0("PC1: ",percentVar[1],"% variance")) +
ylab(paste0("PC2: ",percentVar[2],"% variance")) +
theme_minimal()
# Counts of specific top gene! (important validatition that the normalization, model is working)
d <-plotCounts(dds, gene="MA_10426407g0030", intgroup = (c("treatment","climate")), returnData=TRUE)
d
p <-ggplot(d, aes(x=climate, y=count, shape=climate, colour = treatment)) +
theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.3,h=0), size=3) +
scale_x_discrete(limits=c("CW","HD"))
p
p <-ggplot(d, aes(x=treatment, y=count, shape=climate)) +
theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p
p <-ggplot(d, aes(x=treatment, y=count, shape=climate, colour = treatment)) +
theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.3,h=0), size=3) +
scale_x_discrete(limits=c("C","H","D"))
p
# Heatmap of top 20 genes sorted by pvalue
library(pheatmap)
# Heatmap of top 20 genes sorted by pvalue
install.packages("pheatmap")
library(pheatmap)
topgenes <- head(rownames(res_treatCD),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("treatment","climate")])
pheatmap(mat, annotation_col=df)
day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)
conds10<- subset(conds, day=="10")
dim(conds10)
head(conds10)
