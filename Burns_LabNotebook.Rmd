Title
Author: Kerria Burns
Affiliation: UVM
E-mail contact: Kerria.Burns@uvm.edu
Start Date: 2020-01-13
End Date: 2020-05-08
Project Descriptions: Class notes for ecological genomics
Table of Contents:
Entry 1: 2020-01-13, Monday First day of class
Entry 2: 2020-01-14, Tuesday
Entry 3: 2020-01-15, Wednesday Second day of class Methods info update blitz and computer set-up
Entry 4: 2020-01-16, Thursday
Entry 5: 2020-01-17, Friday
Entry 6: 2020-01-20, Monday
Entry 7: 2020-01-21, Tuesday
Entry 8: 2020-01-22, Wednesday Additional sequencing info updates
Entry 9: 2020-01-23, Thursday
Entry 10: 2020-01-24, Friday
Entry 11: 2020-01-27, Monday Population genomics and paper discussion
Entry 12: 2020-01-28, Tuesday
Entry 13: 2020-01-29, Wednesday
Entry 14: 2020-01-30, Thursday
Entry 15: 2020-01-31, Friday
Entry 16: 2020-02-03, Monday
Entry 17: 2020-02-04, Tuesday
Entry 18: 2020-02-05, Wednesday
Entry 19: 2020-02-06, Thursday
Entry 20: 2020-02-07, Friday
Entry 21: 2020-02-10, Monday
Entry 22: 2020-02-11, Tuesday
Entry 23: 2020-02-12, Wednesday
Entry 24: 2020-02-13, Thursday
Entry 25: 2020-02-14, Friday
Entry 26: 2020-02-17, Monday
Entry 27: 2020-02-18, Tuesday
Entry 28: 2020-02-19, Wednesday
Entry 29: 2020-02-20, Thursday
Entry 30: 2020-02-21, Friday
Entry 31: 2020-02-24, Monday
Entry 32: 2020-02-25, Tuesday
Entry 33: 2020-02-26, Wednesday
Entry 34: 2020-02-27, Thursday
Entry 35: 2020-02-28, Friday
Entry 36: 2020-03-02, Monday
Entry 37: 2020-03-03, Tuesday
Entry 38: 2020-03-04, Wednesday
Entry 39: 2020-03-05, Thursday
Entry 40: 2020-03-06, Friday
Entry 41: 2020-03-09, Monday
Entry 42: 2020-03-10, Tuesday
Entry 43: 2020-03-11, Wednesday
Entry 44: 2020-03-12, Thursday
Entry 45: 2020-03-13, Friday
Entry 46: 2020-03-16, Monday
Entry 47: 2020-03-17, Tuesday
Entry 48: 2020-03-18, Wednesday
## Set your working directory
setwd("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics")

## Import the libraries that we're likely to need in this session
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")

## Import the counts matrix
countsTable <- read.table("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)

## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)

## Let's see how many reads we have from each sample:
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), las=3, cex.names=0.5,names.arg = substring(colnames(countsTableRound),1,13))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd =2)

#What is the average number of counts per gene?
rowSums(countsTableRound)
mean(rowSums(countsTableRound))
median(rowSums(countsTableRound))
#wow this shows dispersion across genes. Mean thrown off by few highly expressed genes. Differnces in magnitude of expression.


#What's the average number of counts per gene per sample?
apply(countsTableRound,2,mean)

## Create a DESeq object and define the experimental design here with the tilde
dds <- DESeqDataSetFromMatrix(countData = countsTableRound,colData = conds, design = ~ pop + day + treatment)
dim(dds)
#[1] 66408    76

# Filter out genes with few reads
dds <- dds[rowSums(counts(dds)) > 760]
dim(dds)
#[1] 23887    76 This is filtering to sum of 76 reads across all samples
#[1] 7884   76 This is filtering to sum of 760 reads across all samples


## Run the DESeq model to test for differential gene expression: 1) estimate size factors (per sample), 2) estimate dispersion (per gene), 3) run negative binomial glm

dds <- DESeq(dds)
resultsNames(dds)
#[1] "Intercept"           
#[2] "pop_BRU_05_vs_ASC_06"
#[3] "pop_CAM_02_vs_ASC_06"
#[4] "pop_ESC_01_vs_ASC_06"
#[5] "pop_JAY_02_vs_ASC_06"
#[6] "pop_KAN_04_vs_ASC_06"
#[7] "pop_LOL_02_vs_ASC_06"
#[8] "pop_MMF_13_vs_ASC_06"
#[9] "pop_NOR_02_vs_ASC_06"
#[10] "pop_XBM_07_vs_ASC_06"
#[11] "day_10_vs_0"         
#[12] "day_5_vs_0"          
#[13] "treatment_D_vs_C"    
#[14] "treatment_H_vs_C"


dds <- DESeqDataSetFromMatrix(countData = countsTableRound,colData = conds, design = ~ climate + day + treatment)
dim(dds)
dds <- DESeq(dds)

# List the results you've generated
resultsNames(dds)
#[1] "Intercept"       
#[2] "climate_HD_vs_CW"
#[3] "day_10_vs_0"     
#[4] "day_5_vs_0"      
#[5] "treatment_D_vs_C"
#[6] "treatment_H_vs_C"


# Order and list and summarize results from specific contrasts
# Here you set your adjusted p-value cutoff, can make summary tables of the number of genes differentially expressed (up- or down-regulated) for each contrast
res <- results(dds,alpha = 0.05)
res <- res[order(res$padj)]
head(res)
#log2 fold change (MLE): treatment H vs C 
#Wald test p-value: treatment H vs C 
#DataFrame with 6 rows and 6 columns
#baseMean
#<numeric>
#   MA_10000213g0010                   0
# MA_10000405g0010 0.00927779777599038
# MA_10000516g0010   0.306727408755282
# MA_10001015g0010  0.0953769494456185
# MA_10001337g0010    10.5864076666598
# MA_10002583g0010  0.0720400016104675
# log2FoldChange
# <numeric>
#   MA_10000213g0010                  NA
# MA_10000405g0010  -0.678234333988712
# MA_10000516g0010   0.674578980909189
# MA_10001015g0010 -0.0643026331356064
# MA_10001337g0010  -0.176203680815192
# MA_10002583g0010  -0.112494012427474
# lfcSE
# <numeric>
#   MA_10000213g0010                NA
# MA_10000405g0010  3.56904296103673
# MA_10000516g0010 0.989443886861717
# MA_10001015g0010  3.56705966952029
# MA_10001337g0010 0.426103598391028
# MA_10002583g0010  3.56871636664819
# stat
# <numeric>
#   MA_10000213g0010                  NA
# MA_10000405g0010  -0.190032549731959
# MA_10000516g0010   0.681775884278587
# MA_10001015g0010 -0.0180267893147562
# MA_10001337g0010  -0.413523099735695
# MA_10002583g0010 -0.0315222620320287
# pvalue
# <numeric>
#   MA_10000213g0010                NA
# MA_10000405g0010 0.849283624250601
# MA_10000516g0010 0.495380675441948
# MA_10001015g0010 0.985617482098602
# MA_10001337g0010 0.679223401788245
# MA_10002583g0010 0.974853038430995
# padj
# <numeric>
#   MA_10000213g0010                NA
# MA_10000405g0010                NA
# MA_10000516g0010                NA
# MA_10001015g0010                NA
# MA_10001337g0010 0.933204889831224
# MA_10002583g0010

summary(res)
# out of 53066 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 15, 0.028%
# LFC < 0 (down)     : 6, 0.011%
# outliers [1]       : 307, 0.58%
# low counts [2]     : 45381, 86%
# (mean count < 8)
# [1] see 'cooksCutoff' argument of ?results
# [2] see 'independentFiltering' argument of ?results

res_treatCD <- results(dds, name="treatment_D_vs_C",alpha=0.05)
res_treatCD <- res_treatCD[order(res_treatCD$padj),]
head(res_treatCD)
# log2 fold change (MLE): treatment D vs C 
# Wald test p-value: treatment D vs C 
# DataFrame with 6 rows and 6 columns
# baseMean
# <numeric>
#   MA_10257300g0010 20.9979917001674
# MA_444738g0020   23.5872071084088
# MA_57964g0010    7.89927388331396
# MA_75192g0010    37.9183573851468
# MA_10428616g0010  35.758883777048
# MA_7017g0010     64.7924705055064
# log2FoldChange
# <numeric>
#   MA_10257300g0010  6.3160877571623
# MA_444738g0020   2.60475479951658
# MA_57964g0010    5.39739873586083
# MA_75192g0010    5.81210235837303
# MA_10428616g0010 3.82582767481363
# MA_7017g0010     2.64414218710183
# lfcSE
# <numeric>
#   MA_10257300g0010 0.761778438070059
# MA_444738g0020   0.330944830911607
# MA_57964g0010    0.694994697724841
# MA_75192g0010    0.768762098604424
# MA_10428616g0010 0.510533466865097
# MA_7017g0010     0.358927431461684
# stat
# <numeric>
#   MA_10257300g0010 8.29123986911983
# MA_444738g0020   7.87066168201399
# MA_57964g0010    7.76610059548648
# MA_75192g0010    7.56033936756775
# MA_10428616g0010 7.49378429254779
# MA_7017g0010     7.36678769949098
# pvalue
# <numeric>
#   MA_10257300g0010 1.12074011571857e-16
# MA_444738g0020   3.52770431249132e-15
# MA_57964g0010    8.09392779867025e-15
# MA_75192g0010    4.02019076294688e-14
# MA_10428616g0010 6.69156646447227e-14
# MA_7017g0010     1.74788498523708e-13
# padj
# <numeric>
#   MA_10257300g0010 1.84910911692407e-12
# MA_444738g0020   2.91017967258971e-11
# MA_57964g0010    4.45139049167535e-11
# MA_75192g0010    1.65822818494651e-10
# MA_10428616g0010 2.20808310194656e-10
# MA_7017g0010     4.80639239523776e-10

summary(res_treatCD)
# out of 53066 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 667, 1.3%
# LFC < 0 (down)     : 414, 0.78%
# outliers [1]       : 307, 0.58%
# low counts [2]     : 36260, 68%
# (mean count < 2)
# [1] see 'cooksCutoff' argument of ?results
# [2] see 'independentFiltering' argument of ?results

##### Data visualization #####
# MA plot
plotMA(res_treatCD,ylim=c(-3,3))

# PCA
vsd <- vst(dds,blind=FALSE)

data <- plotPCA(vsd,intgroup=c("climate","treatment","day"),returnData=TRUE)
percentVar <- round(100 * attr(data,"percentVar"))

ggplot(data, aes(PC1, PC2, color=day, shape=treatment)) +
  geom_point(size=4, alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()

ggplot(data, aes(PC1, PC2, color=climate, shape=treatment)) +
  geom_point(size=4, alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()

# Counts of specific top gene! (important validatition that the normalization, model is working)
d <-plotCounts(dds, gene="MA_10426407g0030", intgroup = (c("treatment","climate")), returnData=TRUE)
d



p <-ggplot(d, aes(x=treatment, y=count, shape=climate, colour = treatment)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.3,h=0), size=3) +
  scale_x_discrete(limits=c("C","H","D"))
p

#add in day somehow

p <-ggplot(d, aes(x=treatment, y=count, shape=climate)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p

# Heatmap of top 20 genes sorted by pvalue
install.packages("pheatmap")
library(pheatmap)
topgenes <- head(rownames(res_treatCD),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("treatment","climate")])
pheatmap(mat, annotation_col=df)


############ Try with only Day 10 data



# grep("10", names(countsTableRound), value = TRUE)
# day10countstable <- subset(countsTableRound, grep("10", names(countsTableRound), value = TRUE)) #doesn't work has to be logical



day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)



conds10<- subset(conds, day=="10")
dim(conds10)
head(conds10)


############ Try with only Day 10 data



# grep("10", names(countsTableRound), value = TRUE)
# day10countstable <- subset(countsTableRound, grep("10", names(countsTableRound), value = TRUE)) #doesn't work has to be logical



day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)



conds10<- subset(conds, day=="10")
dim(conds10)

dds <- DESeqDataSetFromMatrix(countData = day10countstable, colData = conds10,
                              design = ~ climate + treatment + climate:treatment)
Entry 49: 2020-03-19, Thursday
Entry 50: 2020-03-20, Friday
Entry 51: 2020-03-23, Monday
Entry 52: 2020-03-24, Tuesday
Entry 53: 2020-03-25, Wednesday
Entry 54: 2020-03-26, Thursday
Entry 55: 2020-03-27, Friday
Entry 56: 2020-03-30, Monday
Entry 57: 2020-03-31, Tuesday
Entry 58: 2020-04-01, Wednesday
Entry 59: 2020-04-02, Thursday
Entry 60: 2020-04-03, Friday
Entry 61: 2020-04-06, Monday
Entry 62: 2020-04-07, Tuesday
Entry 63: 2020-04-08, Wednesday
Entry 64: 2020-04-09, Thursday
Entry 65: 2020-04-10, Friday
Entry 66: 2020-04-13, Monday
Entry 67: 2020-04-14, Tuesday
Entry 68: 2020-04-15, Wednesday
Entry 69: 2020-04-16, Thursday
Entry 70: 2020-04-17, Friday
Entry 71: 2020-04-20, Monday
Entry 72: 2020-04-21, Tuesday
Entry 73: 2020-04-22, Wednesday
Entry 74: 2020-04-23, Thursday
Entry 75: 2020-04-24, Friday
Entry 76: 2020-04-27, Monday
Entry 77: 2020-04-28, Tuesday
Entry 78: 2020-04-29, Wednesday
Entry 79: 2020-04-30, Thursday
Entry 80: 2020-05-01, Friday
Entry 81: 2020-05-04, Monday
Entry 82: 2020-05-05, Tuesday
Entry 83: 2020-05-06, Wednesday
Entry 84: 2020-05-07, Thursday
Entry 85: 2020-05-08, Friday
Entry 1: 2020-01-13, Monday.
Introductions
What is ecological genomics?
Species interactions at the genomic level
Study of genes and relation to organisms in their environment
In the context of evolution
Overlapping of fields
Popgen: 1920/30s Wright, Fisher, Haldane

Mathematical theory: based on a theoretical unchanging population
Fst population level differentiation
Selection: thinking in terms of the relative fitness of different genotypes
Molecular evolution: Kimura Tajima

How does the DNA reveal the history of an organism/population/species
Can look at pos/neg selection by comparing nonsynonymous to synonymous changes in the DNA
Can look at the nucleotide diversity, processes of evolution can influence diversity stats
Merge these two fields with ecology and NGS -> ecological genomics

Class structure
Mondays: mini lectures/info updates and journal review Wednesdays: Computer lab

Entry 2: 2020-01-14, Tuesday.
Entry 3: 2020-01-15, Wednesday.
How to pick a platform/method
Question
Organisms / sample (tissue type, environmental)
Is there a reference genome?
Ploidy
DNA/RNA/?
Different library prep methods
Whole genome sequencing
RNAseq
Exome capture
GBS/Rad
Amplicon
Bisulfite/ATAC
Sequencing platforms
Illumina
Pacbio/nanopore
Info updates
Chege: Illumina
Video on Illumina platform

Library prep
Cut up DNA/RNA into pieces and attach adapters
Cluster generation
Bind fragments of DNA to lawn of complementary sequences to adapters
Through PCR process our fragments are magnified, to facilitate sequencing
Sequencing by synthesis
Add fluorescent dNTPs
As each base is read an image is stored
Data analysis
Why do we use this method?

MiSeq: 30mill bp /run
HiSeq: 3 bill /run
NovaSeq: 13 bill / run
Sanger: 400 /run
Csenge: PacBio/Nanopore
Two different approaches: SMRT or Synthetic
PacBio and Nanopore both use SMRT method
PacBio
Utilize special flow cell with a bunch of small wells
Polymerase is fixed at the bottom of the well and the DNA passes across the wells
Fluorescence is recorded as each nucleotide is incorporated
Nanopore
directly detects sequence of DNA
Sequence moves through a pore and instead of looking at fluorescence of each base ... has unique sequence signal
These methods are less accurate than short read sequencing and more expensive
Can help with repetitive regions of DNA, get rid of potential gaps, helpful to identify alternative splicing
Erika: RNAseq
Whole transcriptome shotgun sequencing
Uses high throughput NGS technology to characterize gene expression patterns and to identify novel transcripts/molecular markers of interest
Can incorporate into your experimental framework
Advantage: gives functionally relevant information about what is being expressed at that time point. Can also allow you to detect differences among populations (both gene expression and SNP differences).
Limitations: some inherent error, RNA is a less stable molecule can introduce error/bias
Need to be mindful of expression level differences among tissue types, etc.
Workflow: Sample collection (freeze/RNAlater), isolate RNA, quality assessment of RNA (gel or bioanalyzer or qubit), rRNA depletion (selecting for molecules with poly-A tail to enrich for mRNA), fragmentation, cDNA synthesis, adding adapters (amplification element, primary sequencing site, barcode for multiplexing), amplification using PCR, sequence on platform of choice
Zoe: GBS/RADseq
Use restriction sites to fragment DNA
Ligate adapters to each of your fragments with a barcode
Workflow: Extract genomic DNA from your samples, digest with a restriction enzyme, ligate adapters, multiplex individuals, clean up fragments, PCR, check fragment size, send for sequencing
Limitations: fragment bias for what gets amplified
Ben: Bisulfite/ATAC seq
Bisulfite: used to identify methylated cytosine, which typically occurs in CG islands, typical of non-coding DNA or in promotors upstream of genes that aren't constantly expressed.
Workflow: Isolate DNA, treat with sodium bisulfite (converts meytholated Cs into Us), PCR, Sequence samples and compare treated vs untreated samples (these CG islands will differ in their sequence) so this allows you to identify methylated vs non-methylated regions of the genome
CHIPseq: acts at the level of histone modification, chromatin immunoprecipitation
Workflow: introduce a fixative to the DNA, fragment the DNA, introduce an antibody that is specific to your protein of interest which allows your targeted fragments to be precipitated out, decouple sequence and protein, and then you sequence
ATACseq: looks at chromatin state
Workflow: introduce transposons that fragment open chromatin, transposons add adapters to fragments, sequence fragments
HiC seq: identifies all regions where the DNA strand is interacting with itself and sequences them
Entry 4: 2020-01-16, Thursday.
Entry 5: 2020-01-17, Friday.
Entry 6: 2020-01-20, Monday.
Entry 7: 2020-01-21, Tuesday.
Entry 8: 2020-01-22, Wednesday.
Jorge: Amplicon Seq
Uses:

Genome targeting
Detection of hot-spots of mutation
Gene fusion
SNPs
Metagenomics
Workflow:

Sample selection
DNA or RNA extraction
Select amplicon that you will sequence: ITS, CO1, 16S
Library prep
PCR using primers to focus on amplicon of choice
Optional purification step
2nd PCR to attach barcode
Size selection purification to isolate your amplicon
Pool samples
Sequence
Bioinformatic procedure
Quality contreol
trimming
demultiplex
generate your OTUs (operational taxonomic unit)
Alison: Exon capture sequencing
Exon: protein coding region of the gene Exome: portion of the genome that codes for genes

Prevalent in biomedical field and in evolutionary biology
More targeted approach than WGS Biomedical uses:
disease causing variants are more likely to be found in the exome
especially interested for rare diseases
EcoEvo Uses:

Genetic mapping of phenotypic traits
Detect selection (particularly helpful for non-model organisms)
Used in phylogenetic reconstruction
Can also be used to analyze ancient DNA
Workflow:

Sample collection & extraction
Fragmentation of DNA
Enriching library using probes
PCR: need to have primers designed
Denovo: create new probes, need some knowledge of transcriptome/RADseq/WGS
Divergent annotated genome: probes based on relatively close relative, requires annotate genomes
DNA purification
Quality control
Entry 9: 2020-01-23, Thursday.
Entry 10: 2020-01-24, Friday.
Entry 11: 2020-01-27, Monday.
#####Steve lecture on population genomics
variation across the genome
  statistally capture variation with statistics
    number of SNPs dependent on location in chromosome (LD)
      selection acts locally across chromosome
      find outliers
    demographic processes act globally
      mean and distribution
    demographic history
      Ne: idealized Wright-Fisher population
      -migration
      -genetic populations (demes)
        divergence times between
      -bottleneck, expansion, splitting
      -coalescent theory
        -branch of population genetics
        -probability that two sampled allele copies share a common ancestor
          -probability that two haplotypes originated from the same genotype
      -coalescence speeds up with lower population size
        -1/2Ne
        -due to increased effects of genetic drift in smaller populations
        -estimation migration through whether there are allele copies with much deeper coalescence
          -allele copy originated far back in common ancestor but migrated
            -common ancestor not present since population was unified
        -presence of mutation distinct from geneaology
          -fuzzy image
        -almost all alleles are rare
        -if population is growing, see a lot of rare mutations
          -frequency of rare alleles is very high, frequency of common alleles is low
            -rate at which mutations enter population is proportional to effective population size times mutation rate
              -theta=Ne*u
        -bottlenecked populations lose rare alleles and retain common alleles
      -effect of selection on allele frequencies depends on type
        -focus here is positive selection
      -pi=nucleotide diversity
        -average pairwise differences
          -sample two individuals: how many SNPs do they differ by in the chromosome?
        -LD measures extent of correlation
          -hitchhiking (not under seleciton themselves, just along for the ride with selected sites)
      -selective sweep has same signature as population expansion
      -Taj D very negative in case of selective sweep or population expansion
        -to distinguish selection, have to pick out local signals
Entry 12: 2020-01-28, Tuesday.
Entry 13: 2020-01-29, Wednesday.

URL: [what to hyperlink](URL)

embed code: /// cd ~/mydata ///

This is where the class data are `/data/project.data`

Phred score (probability that reader misread the nucleotide on the flow cell (could still be the wrong base)): p=10^(-Q/10)
e.g., p=10^(-38/10)=0.0038 -> a good score

XFS
run fastqc on trimmed sequences
did it clean things up? did quality scores improve? especially at the beginning and end?
just on cleaned, paired reads.

look back at cd (ll) /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/
```
#!/bin/bash

cd ~/Ecological_Genomics/myresults

#creating new dir to store results
mkdir fastqc

for file in /data/project_data/RS_ExomeSeq/fastq/edge_fastq/XFS*fastq.gz

do

fastqc ${file} -o fastqc/

done
```
Entry 14: 2020-01-30, Thursday.
Entry 15: 2020-01-31, Friday.
Entry 16: 2020-02-03, Monday.
Entry 17: 2020-02-04, Tuesday.
Entry 18: 2020-02-05, Wednesday.

#!/bin/bash

#This script will run the read mapping using "bam"

ref="/data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa"

#Write a loop to map each individual within my population.

for forward in ${input}*_R1.cl.pd.fq

do
  reverse=${forward/_R1.cl.pd.fq/_R2.cl.pd.fq}
  f=${forward/_R1.cl.pd.fq/}
  name=`basename ${f}`
  bwa mem -t 1 -M ${ref} ${forward} ${reverse} > ${output}/BWA/${name}.sam
done


#!/bin/bash   
 
cd /data/project_data/RS_ExomeSeq/fastq/edge_fastq  
 
for R1 in XFS*R1_fastq.gz  

do 
 
	R2=${R1/_R1_fastq.gz/_R2_fastq.gz}
	f=${R1/_R1_fastq.gz/}
	name=`basename ${f}`

	java -classpath /data/popgen/Trimmomatic-0.33/trimmomatic-0.33.jar org.usadellab.trimmomatic.TrimmomaticPE \
        -threads 1 \
        -phred33 \
         "$R1" \
         "$R2" \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/${name}_R1.cl.pd.fq \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/unpairedcleanreads/${name}_R1.cl.un.fq \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/${name}_R2.cl.pd.fq \
         /data/project_data/RS_ExomeSeq/fastq/edge_fastq/unpairedcleanreads/${name}_R2.cl.un.fq \
        ILLUMINACLIP:/data/popgen/Trimmomatic-0.33/adapters/TruSeq3-PE.fa:2:30:10 \
        LEADING:20 \
        TRAILING:20 \
        SLIDINGWINDOW:6:20 \
        MINLEN:35 
 
done 
Entry 19: 2020-02-06, Thursday.
Entry 20: 2020-02-07, Friday.
Entry 21: 2020-02-10, Monday.
Entry 22: 2020-02-11, Tuesday.
Entry 23: 2020-02-12, Wednesday.
#!/bin/bash

#We'll use this wrapper to run our different scripts.

#Path to my repo

myrepo="/users/k/b/kburns/EcologicalGenomics/"

#My population
mypop="XFS"

#Directory to our cleaned and paired reads
input="/data/project_data/RS_ExomeSeq/fastq/edge_fastq/pairedcleanreads/${mypop}"

#Directory to store the outputs on our mapping
output="/data/project_data/RS_ExomeSeq/mapping"


#Run mapping.sh
#source ./mapping.sh

#Run the post-processing steps
source ./process_bam.sh


#for f in ${output}/BWA/${mypop}*.sam

#do

#  out=${f/.sam/}
 # sambamba-0.7.1-linux-static view -S --format=bam ${f} -o ${out}.bam
  #samtools sort ${out}.bam -o ${out}.sorted.bam

#done

#Now, let's remove the PCR duplicates
#for file in ${output}/BWA/${mypop}*.sorted.bam

#do
 # f=${file/.sorted.bam/}
  #sambamba-0.7.1-linux-static markdup -r -t 1 ${file} ${f}.sorted.rmdup
#done

#Now, to finish we'll index our files
for file in ${output}/BWA/${mypop}*.sorted.rmdup.bam

do
  samtools index ${file}
done
To account for low read scores, use genotype likelihood to account for uncertainty.
Entry 26: 2020-02-17, Monday.
Entry 27: 2020-02-18, Tuesday.
Entry 28: 2020-02-19, Wednesday.
ANGSD script:
myrepo="/users/k/b/kburns/EcologicalGenomics"

mkdir ${myrepo}/myresults/ANGSD

output="${myrepo}/myresults/ANGSD"

mypop="XFS"

ls /data/project_data/RS_ExomeSeq/mapping/BWA/${mypop}_*sorted.rm*.bam >${output}/${mypop}_bam.list

REF="/data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa"

# Estimating GL's and allele frequencies for all sites with ANGSD

ANGSD -b ${output}/${mypop}_bam.list \
-ref ${REF} -anc ${REF} \
-out ${output}/${mypop}_allsites \
-nThreads 1 \
-remove_bads 1 \
-C 50 \
-baq 1 \
-minMapQ 20 \
-minQ 20 \
-setMinDepth 3 \
-minInd 2 \
-setMinDepthInd 1 \
-setMaxDepthInd 17 \
-skipTriallelic 1 \
-GL 1 \
-doCounts 1 \
-doMajorMinor 1 \
-doMaf 1 \
-doSaf 1 \
-doHWE 1 \
# -SNP_pval 1e-6



ANGSD -b ${output}/${mypop}_bam.list \
-ref ${REF}  \
-out ${output}/${mypop}_folded_allsites \
-nThreads 1 \
-remove_bads 1 \
-C 50 \
-baq 1 \
-minMapQ 20 \
-minQ 20 \
-setMinDepth 3 \
-minInd 2 \
-setMinDepthInd 1 \
-setMaxDepthInd 17 \
-skipTriallelic 1 \
-GL 1 \
-doCounts 1 \
-doMajorMinor 1 \
-doMaf 1 \
-doSaf 1 \
-fold 1 




Estimating rough SFS
.sfs
Estimate SFS using .sfs as a prior
doTheta=4Neu
theta_stats





setwd("~/Documents/GitHub/EcologicalGenomics/myresults")

list.files()

SFS <- scan("XFS_outFold.sfs")

sumSFS <- sum(SFS)


pctPoly = 100*(1-(SFS[1]/sumSFS))

plotSFS <- SFS[-c(1,length(SFS))]

barplot(plotSFS)

div <- read.table("XFS_folded_allsites.thetas.idx.pestPG")

colnames(div)=c("window","chrname","wincenter","tW","tP","tF","tH","tL","tajD","fulif","fuliD","fayH","zengsE","numSites")

div$tWpersite=div$tW/div$numSites
div$tPpersite=div$tP/div$numSites

hist(div$tWpersite-div$tPpersite)

pdf("XFS_diversity_stats.pdf")
par(mfrow=c(2,2))
hist(div$tWpersite, col="gray",xlab="Theta-W",main="")
hist(div$tPpersite, col="gray",xlab="Theta-Pi",main="")
hist(div$tajD, col="gray",xlab="Tajima's D",main="")
barplot(plotSFS)
dev.off()

summary(div)

head(div)

Entry 29: 2020-02-20, Thursday.
Entry 30: 2020-02-21, Friday.
Entry 31: 2020-02-24, Monday.

Transcriptomics!!

Workflow

-Careful experimental design
	considering questions/hypotheses (broad or a priori)
	factors (populations, treatments, tissue, sex)
-Experiment
	control environment (did an individual experience a really hot tide the previous day? is one well fed and going into reproduction?)
	sample tissues and individuals
	save your RNA quickly (flash freeze! it's highly labile)
		refer to transcriptomics technical details (extract, prep, sequence)
-process and analyze sequence data
	check quality, clean, check quality (working with fastQ files)
	map to reference and extract count data
		looking at abundance (RNAseq only read one direction of polarity)
	Normalize for variation among samples
		if one happened to map very well, you'll have a ton of data
		results in a really nice data matrix (count data matrix)
			which population was it in, what tissue, etc.
				use to test for differences in expression
					using ANOVA design, e.g.
			looking at counts (proxy for expression magnitude): two conditions, multiple families (look at degree of expression (average across replicates) for a given gene)
-integrate (with other data types (different genetic diversity statistics, SNPS, proteomics, environmental data))
	functional enrichment, network analyses (all genes in regulatory network, with a particular function)
	
Entry 32: 2020-02-25, Tuesday.


Entry 33: 2020-02-26, Wednesday.
<<<<<<< HEAD

=======
>>>>>>> 9c182fb96c096f1cceae3882ee956a072731eb25
-only 3' RNA
-took from two environments, hot/dry and cool/wet, then raised in common garden.
-took cone tissue and ground up, extracted RNA

Factors
Treatments: C, H, D
Source/climate: H/D, C/W
Time: 0, 5, 10

What questions can we ask with these data?
1. Do individuals from difference climate sources have different gene expression in common environments?
  -each condition
  - exp ~ clim + trt
2. Do indivduals from different source climates have different gene expression at different time points?
  -an interaction between source climate and time
  -exp ~ clim + time + clim*time + family (probably can't include? random effect)
  -exp ~ clim + trt + clim*trt
  
1. Do family from different sources differ in gene expression?
2. Transcriptome wide response to heat stress? Water stress?

Population:
LOL: C, D

Entry 34: 2020-02-27, Thursday.
Entry 35: 2020-02-28, Friday.
Entry 36: 2020-03-02, Monday.
Entry 37: 2020-03-03, Tuesday.
Entry 38: 2020-03-04, Wednesday.

mapped the population sequences to the reference transcriptome.



Entry 39: 2020-03-05, Thursday.
Entry 40: 2020-03-06, Friday.
Entry 41: 2020-03-09, Monday.
Entry 42: 2020-03-10, Tuesday.
Entry 43: 2020-03-11, Wednesday.
Entry 44: 2020-03-12, Thursday.
Entry 45: 2020-03-13, Friday.
Entry 46: 2020-03-16, Monday.
Entry 47: 2020-03-17, Tuesday.
Entry 48: 2020-03-18, Wednesday.
Entry 49: 2020-03-19, Thursday.
Entry 50: 2020-03-20, Friday.
Entry 51: 2020-03-23, Monday.

ALL DAYS
## Set your working directory
setwd("~/github/2020_Ecological_Genomics")

## Import the libraries that we're likely to need in this session
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")

## Import the counts matrix
countsTable <- read.table("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)

## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)

############ Try with only Day 10 data

# grep("10", names(countsTableRound), value = TRUE)
# day10countstable <- subset(countsTableRound, grep("10", names(countsTableRound), value = TRUE)) #doesn't work has to be logical

day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)

conds10<- subset(conds, day=="10")
dim(conds10)
head(conds10)

## Let's see how many reads we have from each sample:
colSums(countsTableRound)
mean(colSums(countsTableRound))
barplot(colSums(countsTableRound), las=3, cex.names=0.5,names.arg = substring(colnames(countsTableRound),1,13))
abline(h=mean(colSums(countsTableRound)), col="blue", lwd =2)

# What's the average number of counts per gene
rowSums(countsTableRound)
mean(rowSums(countsTableRound))
median(rowSums(countsTableRound))
# wow! This shows dispersion across genes - differences in magnitude of expression

# What's the average number of counts per gene per sample
apply(countsTableRound,2,mean)

## Create a DESeq object and define the experimental design here with the tilde

dds <- DESeqDataSetFromMatrix(countData = countsTableRound, colData = conds, 
                              design = ~ climate + day + treatment)
dim(dds)
# [1] 66408    76

# Filter out genes with few reads 

dds <- dds[rowSums(counts(dds)) > 76]
dim(dds)
# [1] 23887    76  This is filtering to sum of 76 reads across all samples
# [1] 7884   76  This is filtering to sum of 760 reads across all samples

## Run the DESeq model to test for differential gene expression: 
# 1) estimate size factors (per sample), 2) estimate dispersion (per gene), 
# 3) run negative binomial glm
dds <- DESeq(dds)

# List the results you've generated
resultsNames(dds)
# Running the model: design = ~ pop + day + treatment
# [1] "Intercept"            "pop_BRU_05_vs_ASC_06" "pop_CAM_02_vs_ASC_06"
# [4] "pop_ESC_01_vs_ASC_06" "pop_JAY_02_vs_ASC_06" "pop_KAN_04_vs_ASC_06"
# [7] "pop_LOL_02_vs_ASC_06" "pop_MMF_13_vs_ASC_06" "pop_NOR_02_vs_ASC_06"
# [10] "pop_XBM_07_vs_ASC_06" "day_10_vs_0"          "day_5_vs_0"          
# [13] "treatment_D_vs_C"     "treatment_H_vs_C"

# Running the model: design = ~ climate + day + treatment
# [1] "Intercept"        "climate_HD_vs_CW" "day_10_vs_0"      "day_5_vs_0"      
# [5] "treatment_D_vs_C" "treatment_H_vs_C"


# Order and list and summarize results from specific contrasts
# Here you set your adjusted p-value cutoff, can make summary tables of the number of genes differentially expressed (up- or down-regulated) for each contrast
res <- results(dds, alpha = 0.05)
res <- res[order(res$padj),]
head(res)

# log2 fold change (MLE): treatment H vs C 
# Wald test p-value: treatment H vs C 
# DataFrame with 6 rows and 6 columns
# baseMean    log2FoldChange             lfcSE              stat
# <numeric>         <numeric>         <numeric>         <numeric>
#   MA_172878g0010   15.8548874481417  2.26899213338594  0.44065452286252  5.14914068882447
# MA_107783g0020    6.6082118492291 -1.96824414729957 0.394042285152064 -4.99500744327481
# MA_28973g0010    18.8813749792546  -1.9664671947209 0.412333404130031 -4.76911929769524
# MA_10434037g0010   5.611769238156   2.1853605976071  0.49671691935347  4.39960974240937
# MA_10426002g0010 10.8980752578363 -1.20767724886483 0.283132420279441 -4.26541491671245
# MA_10429525g0010 60.5937645508928  1.17170086164903 0.281505776107537  4.16226223792093
# pvalue                padj
# <numeric>           <numeric>
#   MA_172878g0010   2.61682549726074e-07 0.00249278796869058
# MA_107783g0020   5.88334982423675e-07 0.00280223952128396
# MA_28973g0010    1.85033065465192e-06 0.00587541660540472
# MA_10434037g0010  1.0844572516541e-05  0.0258263494481425
# MA_10426002g0010 1.99531043147766e-05  0.0357522692442608
# MA_10429525g0010 3.15110173906545e-05  0.0357522692442608

summary(res)
# out of 23887 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 16, 0.067%
# LFC < 0 (down)     : 3, 0.013%
# outliers [1]       : 61, 0.26%
# low counts [2]     : 14300, 60%

res_treatCD <- results(dds, name="treatment_D_vs_C", alpha=0.05)
res_treatCD <- res_treatCD[order(res_treatCD$padj),]
head(res_treatCD)
# log2 fold change (MLE): treatment D vs C 
# Wald test p-value: treatment D vs C 
# DataFrame with 6 rows and 6 columns
# baseMean   log2FoldChange             lfcSE             stat
# <numeric>        <numeric>         <numeric>        <numeric>
#   MA_10257300g0010 20.9979917001674  6.3160877571623 0.761778438070059 8.29123986911983
# MA_444738g0020   23.5872071084088 2.60491779951534 0.331247263623815 7.86396775332654
# MA_57964g0010    7.89927388331396 5.39652442842906 0.688793826922627 7.83474563432065
# MA_75192g0010    37.9183573851468 5.81210235837303 0.768762098604424 7.56033936756775
# MA_10428616g0010  35.758883777048 3.82582283371241 0.510641392538861 7.49219097709799
# MA_7017g0010     64.7924705055064 2.64439151272771 0.360360746749988 7.33817857959526
# pvalue                 padj
# <numeric>            <numeric>
#   MA_10257300g0010 1.12074011571854e-16 1.84462615646114e-12
# MA_444738g0020   3.72153387856494e-15 2.57743989393094e-11
# MA_57964g0010    4.69792799185419e-15 2.57743989393094e-11
# MA_75192g0010    4.02019076294682e-14 1.65420799418354e-10
# MA_10428616g0010 6.77332669682435e-14 2.22964368206064e-10
# MA_7017g0010     2.16520151829775e-13 5.93950863161046e-10

summary(res_treatCD)
# out of 23887 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 678, 2.8%
# LFC < 0 (down)     : 424, 1.8%
# outliers [1]       : 61, 0.26%
# low counts [2]     : 7367, 31%

##### Data visualization #####


# MA plot
plotMA(res_treatCD,ylim=c(-3,3))

# PCA
vsd <- vst(dds, blind=FALSE)

data <- plotPCA(vsd,intgroup=c("climate","treatment","day"),returnData=TRUE)
percentVar <- round(100 * attr(data, "percentVar"))

data$treatment <- factor(data$treatment, levels=c("C","H","D"), labels = c("C","H","D"))
data$day <- factor(data$day, levels=c("0","5","10"), labels = c("0","5","10"))


ggplot(data, aes(PC1, PC2, color=pop, shape=treatment)) +
  geom_point(size=4, alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()

# Counts of specific top gene! (important validatition that the normalization, model is working)
d <-plotCounts(dds, gene="MA_7017g0010", intgroup = (c("treatment","climate","day")), returnData=TRUE)
d

p <-ggplot(d, aes(x=treatment, y=count, color=day, shape=climate)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.3,h=0), size=3) +
  scale_x_discrete(limits=c("C","H","D"))
p

p <-ggplot(d, aes(x=treatment, y=count, shape=climate)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p

# Heatmap of top 20 genes sorted by pvalue

library(pheatmap)
topgenes <- head(rownames(res_treatCD),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("treatment","climate","day")])
pheatmap(mat, annotation_col=df)

ONLY DAY 10
## Set your working directory
setwd("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics")

## Import the libraries that we're likely to need in this session
library(DESeq2)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggpubr)
library(wesanderson)
library(vsn)  ### First: BiocManager::install("vsn") AND BiocManager::install("hexbin")

## Import the counts matrix
countsTable <- read.table("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_cds2kb_countsMatrix.txt", header=TRUE, row.names=1)
head(countsTable)
dim(countsTable)
countsTableRound <- round(countsTable) # Need to round because DESeq wants only integers
head(countsTableRound)

## Import the samples description table - links each sample to factors of the experimental design.
# Need the colClasses otherwise imports "day" as numeric which DESeq doesn't like, coula altneratively change to d0, d5, d10
conds <- read.delim("C:/Users/kmb057/Documents/GitHub/EcologicalGenomics/RS_counts_samples/RS_samples.txt", header=TRUE, stringsAsFactors = TRUE, row.names=1, colClasses=c('factor', 'factor', 'factor', 'factor'))
head(conds)
dim(conds)

############ Try with only Day 10 data

# grep("10", names(countsTableRound), value = TRUE)
# day10countstable <- subset(countsTableRound, grep("10", names(countsTableRound), value = TRUE)) #doesn't work has to be logical

day10countstable <- countsTableRound %>% select(contains("10"))
dim(day10countstable)

conds10<- subset(conds, day=="10")
dim(conds10)
head(conds10)

## Let's see how many reads we have from each sample:
colSums(day10countstable)
mean(colSums(day10countstable))
barplot(colSums(day10countstable), las=3, cex.names=0.5,names.arg = substring(colnames(day10countstable),1,13))
abline(h=mean(colSums(day10countstable)), col="blue", lwd =2)

# What's the average number of counts per gene
rowSums(day10countstable)
mean(rowSums(day10countstable))
median(rowSums(day10countstable))
# wow! This shows dispersion across genes - differences in magnitude of expression

# What's the average number of counts per gene per sample
apply(countsTableRound,2,mean)

## Create a DESeq object and define the experimental design here with the tilde

dds <- DESeqDataSetFromMatrix(countData = day10countstable, colData = conds10, 
                              design = ~ climate + treatment + climate:treatment)
dim(dds)
# [1] 66408    30

# Filter out genes with few reads 

dds <- dds[rowSums(counts(dds)) > 30]
dim(dds)
# 24300    30
## Run the DESeq model to test for differential gene expression: 
# 1) estimate size factors (per sample), 2) estimate dispersion (per gene), 
# 3) run negative binomial glm
dds <- DESeq(dds)

# List the results you've generated
resultsNames(dds)
# Running the model: design = ~ climate + treatment + climate:treatment

# [1] "Intercept"            "climate_HD_vs_CW"     "treatment_D_vs_C"    
# [4] "treatment_H_vs_C"     "climateHD.treatmentD" "climateHD.treatmentH"


# Order and list and summarize results from specific contrasts
# Here you set your adjusted p-value cutoff, can make summary tables of the number of genes differentially expressed (up- or down-regulated) for each contrast
res <- results(dds, name="treatment_D_vs_C", alpha = 0.05)
res <- res[order(res$padj),]
head(res)

# log2 fold change (MLE): treatment H vs C 
# Wald test p-value: treatment H vs C 
# DataFrame with 6 rows and 6 columns
# baseMean    log2FoldChange             lfcSE              stat
# <numeric>         <numeric>         <numeric>         <numeric>
#   MA_172878g0010   15.8548874481417  2.26899213338594  0.44065452286252  5.14914068882447
# MA_107783g0020    6.6082118492291 -1.96824414729957 0.394042285152064 -4.99500744327481
# MA_28973g0010    18.8813749792546  -1.9664671947209 0.412333404130031 -4.76911929769524
# MA_10434037g0010   5.611769238156   2.1853605976071  0.49671691935347  4.39960974240937
# MA_10426002g0010 10.8980752578363 -1.20767724886483 0.283132420279441 -4.26541491671245
# MA_10429525g0010 60.5937645508928  1.17170086164903 0.281505776107537  4.16226223792093
# pvalue                padj
# <numeric>           <numeric>
#   MA_172878g0010   2.61682549726074e-07 0.00249278796869058
# MA_107783g0020   5.88334982423675e-07 0.00280223952128396
# MA_28973g0010    1.85033065465192e-06 0.00587541660540472
# MA_10434037g0010  1.0844572516541e-05  0.0258263494481425
# MA_10426002g0010 1.99531043147766e-05  0.0357522692442608
# MA_10429525g0010 3.15110173906545e-05  0.0357522692442608

summary(res)
# out of 23887 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 16, 0.067%
# LFC < 0 (down)     : 3, 0.013%
# outliers [1]       : 61, 0.26%
# low counts [2]     : 14300, 60%

res_interClimTreat <- results(dds, name="climateHD.treatmentD", alpha=0.05)
res_interClimTreat <- res_interClimTreat[order(res_interClimTreat$padj),]
head(res_interClimTreat)
# log2 fold change (MLE): treatment D vs C 
# Wald test p-value: treatment D vs C 
# DataFrame with 6 rows and 6 columns
# baseMean   log2FoldChange             lfcSE             stat
# <numeric>        <numeric>         <numeric>        <numeric>
#   MA_10257300g0010 20.9979917001674  6.3160877571623 0.761778438070059 8.29123986911983
# MA_444738g0020   23.5872071084088 2.60491779951534 0.331247263623815 7.86396775332654
# MA_57964g0010    7.89927388331396 5.39652442842906 0.688793826922627 7.83474563432065
# MA_75192g0010    37.9183573851468 5.81210235837303 0.768762098604424 7.56033936756775
# MA_10428616g0010  35.758883777048 3.82582283371241 0.510641392538861 7.49219097709799
# MA_7017g0010     64.7924705055064 2.64439151272771 0.360360746749988 7.33817857959526
# pvalue                 padj
# <numeric>            <numeric>
#   MA_10257300g0010 1.12074011571854e-16 1.84462615646114e-12
# MA_444738g0020   3.72153387856494e-15 2.57743989393094e-11
# MA_57964g0010    4.69792799185419e-15 2.57743989393094e-11
# MA_75192g0010    4.02019076294682e-14 1.65420799418354e-10
# MA_10428616g0010 6.77332669682435e-14 2.22964368206064e-10
# MA_7017g0010     2.16520151829775e-13 5.93950863161046e-10

summary(res_interClimTreat)
# out of 23887 with nonzero total read count
# adjusted p-value < 0.05
# LFC > 0 (up)       : 678, 2.8%
# LFC < 0 (down)     : 424, 1.8%
# outliers [1]       : 61, 0.26%
# low counts [2]     : 7367, 31%




# MA plot
plotMA(res_interClimTreat,ylim=c(-10,10))

# PCA
vsd <- vst(dds, blind=FALSE)

data <- plotPCA(vsd,intgroup=c("climate","treatment","day"),returnData=TRUE)
percentVar <- round(100 * attr(data, "percentVar"))

data$treatment <- factor(data$treatment, levels=c("C","H","D"), labels = c("C","H","D"))
data$day <- factor(data$day, levels=c("0","5","10"), labels = c("0","5","10"))


ggplot(data, aes(PC1, PC2, color=pop, shape=climate)) +
  geom_point(size=4, alpha=0.85) +
  xlab(paste0("PC1: ",percentVar[1],"% variance")) +
  ylab(paste0("PC2: ",percentVar[2],"% variance")) +
  theme_minimal()

# Counts of specific top gene! (important validatition that the normalization, model is working)
d <-plotCounts(dds, gene="MA_7017g0010", intgroup = (c("treatment","climate","day")), returnData=TRUE)
d

p <-ggplot(d, aes(x=treatment, y=count, color=climate)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p <- p + geom_point(position=position_jitter(w=0.3,h=0), size=3) +
  scale_x_discrete(limits=c("C","H","D"))
p

p <-ggplot(d, aes(x=treatment, y=count, color=climate)) + 
  theme_minimal() + theme(text = element_text(size=20), panel.grid.major=element_line(colour="grey"))
p

# Heatmap of top 20 genes sorted by pvalue

library(pheatmap)
topgenes <- head(rownames(res_treatCD),20)
mat <- assay(vsd)[topgenes,]
mat <- mat - rowMeans(mat)
df <- as.data.frame(colData(dds)[,c("treatment","climate","day")])
pheatmap(mat, annotation_col=df)





Entry 52: 2020-03-24, Tuesday.
Entry 53: 2020-03-25, Wednesday.
Entry 54: 2020-03-26, Thursday.
Entry 55: 2020-03-27, Friday.
Entry 56: 2020-03-30, Monday.
Entry 57: 2020-03-31, Tuesday.
Entry 58: 2020-04-01, Wednesday.
Entry 59: 2020-04-02, Thursday.
Entry 60: 2020-04-03, Friday.
Entry 61: 2020-04-06, Monday.
Entry 62: 2020-04-07, Tuesday.
Entry 63: 2020-04-08, Wednesday.
Entry 64: 2020-04-09, Thursday.
Entry 65: 2020-04-10, Friday.
Entry 66: 2020-04-13, Monday.
Entry 67: 2020-04-14, Tuesday.
Entry 68: 2020-04-15, Wednesday.
Entry 69: 2020-04-16, Thursday.
Entry 70: 2020-04-17, Friday.
Entry 71: 2020-04-20, Monday.
Entry 72: 2020-04-21, Tuesday.
Entry 73: 2020-04-22, Wednesday.
Entry 74: 2020-04-23, Thursday.
Entry 75: 2020-04-24, Friday.
Entry 76: 2020-04-27, Monday.
Entry 77: 2020-04-28, Tuesday.
Entry 78: 2020-04-29, Wednesday.
Entry 79: 2020-04-30, Thursday.
Entry 80: 2020-05-01, Friday.
Entry 81: 2020-05-04, Monday.
Entry 82: 2020-05-05, Tuesday.
Entry 83: 2020-05-06, Wednesday.
Entry 84: 2020-05-07, Thursday.
Entry 85: 2020-05-08, Friday.
